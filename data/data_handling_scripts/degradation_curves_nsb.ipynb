{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping data for model\n",
    "### In this file, we will take the data that has been gathered and harmonized and we will fit it, create scenarios, and save it as a structured array for the model. Since we would like to keep the flexibility with excel, we will also save it in an ODYM compatible format and create a file that can do the reverse: if teh excel file is eddited, so is the array. This will be a separate script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ODYM_Classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xm/bmpfd0t11s1g959jbbgj_yz80000gn/T/ipykernel_49715/3391651010.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mDataPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'docs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mODYM_Classes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsc\u001b[0m \u001b[0;31m# import the ODYM class file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mODYM_Functions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsf\u001b[0m \u001b[0;31m# import the ODYM function file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdynamic_stock_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdsm\u001b[0m \u001b[0;31m# import the dynamic stock model library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ODYM_Classes'"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "# Load a local copy of the current ODYM branch:\n",
    "from asyncio import new_event_loop\n",
    "from curses.panel import bottom_panel\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from seaborn.palettes import color_palette\n",
    "import xlrd\n",
    "import pylab\n",
    "from copy import deepcopy\n",
    "import logging as log\n",
    "import xlwt\n",
    "import tqdm\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib\n",
    "xlrd.xlsx.Element_has_iter = True\n",
    "\n",
    "mpl_logger = log.getLogger(\"matplotlib\")\n",
    "mpl_logger.setLevel(log.WARNING)  \n",
    "# For Ipython Notebook only\n",
    "### Preamble\n",
    "\n",
    "# add ODYM module directory to system path, relative\n",
    "MainPath = os.path.join(os.getcwd(), 'odym', 'modules')\n",
    "sys.path.insert(0, MainPath)\n",
    "\n",
    "# add ODYM module directory to system path, absolute\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'odym', 'modules'))\n",
    "\n",
    "# Specify path to dynamic stock model and to datafile, relative\n",
    "DataPath = os.path.join( 'docs', 'files')\n",
    "\n",
    "# Specify path to dynamic stock model and to datafile, absolute\n",
    "DataPath = os.path.join(os.getcwd(), 'docs', 'Files')\n",
    "\n",
    "import ODYM_Classes as msc # import the ODYM class file\n",
    "import ODYM_Functions as msf # import the ODYM function file\n",
    "import dynamic_stock_model as dsm # import the dynamic stock model library\n",
    "\n",
    "# Initialize loggin routine\n",
    "log_verbosity = eval(\"log.DEBUG\")\n",
    "log_filename = 'LogFileTest.md'\n",
    "[Mylog, console_log, file_log] = msf.function_logger(log_filename, os.getcwd(),\n",
    "                                                     log_verbosity, log_verbosity)\n",
    "Mylog.info('### 1. - Initialize.')\n",
    "\n",
    "#Read main script parameters\n",
    "#Load project-specific config file\n",
    "ProjectSpecs_ConFile = 'ODYM_Config_Vehicle_System.xlsx'\n",
    "Model_Configfile     = xlrd.open_workbook(os.path.join(DataPath, ProjectSpecs_ConFile))\n",
    "# Model_Configfile     = pd.read_excel(os.path.join(DataPath, ProjectSpecs_ConFile), engine = 'openpyxl')\n",
    "ScriptConfig         = {'Model Setting': Model_Configfile.sheet_by_name('Config').cell_value(3,3)} # Dictionary with config parameters\n",
    "Model_Configsheet    = Model_Configfile.sheet_by_name('Setting_' + ScriptConfig['Model Setting'])\n",
    "\n",
    "Name_Scenario        = Model_Configsheet.cell_value(3,3)\n",
    "print(Name_Scenario)\n",
    "\n",
    "#Read control and selection parameters into dictionary\n",
    "ScriptConfig         = msf.ParseModelControl(Model_Configsheet,ScriptConfig)\n",
    "\n",
    "Mylog.info('Read and parse config table, including the model index table, from model config sheet.')\n",
    "IT_Aspects,IT_Description,IT_Dimension,IT_Classification,IT_Selector,IT_IndexLetter,\\\n",
    "PL_Names,PL_Description,PL_Version,PL_IndexStructure,PL_IndexMatch,PL_IndexLayer,\\\n",
    "PrL_Number,PrL_Name,PrL_Comment,PrL_Type,ScriptConfig = msf.ParseConfigFile(Model_Configsheet,ScriptConfig,Mylog)    \n",
    "\n",
    "class_filename       = 'ODYM_Classifications_Master_Vehicle_System.xlsx'\n",
    "Classfile            = xlrd.open_workbook(os.path.join(DataPath,class_filename))\n",
    "Classsheet           = Classfile.sheet_by_name('MAIN_Table')\n",
    "MasterClassification = msf.ParseClassificationFile_Main(Classsheet,Mylog)\n",
    "\n",
    "\n",
    "Mylog.info('Define model classifications and select items for model classifications according to information provided by config file.')\n",
    "ModelClassification  = {} # Dict of model classifications\n",
    "for m in range(0,len(IT_Aspects)):\n",
    "    ModelClassification[IT_Aspects[m]] = deepcopy(MasterClassification[IT_Classification[m]])\n",
    "    EvalString = msf.EvalItemSelectString(IT_Selector[m],len(ModelClassification[IT_Aspects[m]].Items))\n",
    "    if EvalString.find(':') > -1: # range of items is taken\n",
    "        RangeStart = int(EvalString[0:EvalString.find(':')])\n",
    "        RangeStop  = int(EvalString[EvalString.find(':')+1::])\n",
    "        ModelClassification[IT_Aspects[m]].Items = ModelClassification[IT_Aspects[m]].Items[RangeStart:RangeStop]           \n",
    "    elif EvalString.find('[') > -1: # selected items are taken\n",
    "        ModelClassification[IT_Aspects[m]].Items = [ModelClassification[IT_Aspects[m]].Items[i] for i in eval(EvalString)]\n",
    "    elif EvalString == 'all':\n",
    "        None\n",
    "    else:\n",
    "        Mylog.error('Item select error for aspect ' + IT_Aspects[m] + ' were found in datafile.')\n",
    "        break\n",
    "\n",
    "# Define model index table and parameter dictionary\n",
    "Mylog.info('### 2.2 - Define model index table and parameter dictionary')\n",
    "Model_Time_Start = int(min(ModelClassification['Time'].Items))\n",
    "Model_Time_End   = int(max(ModelClassification['Time'].Items))\n",
    "Model_Duration   = Model_Time_End - Model_Time_Start + 1\n",
    "\n",
    "Mylog.info('Define index table dataframe.')\n",
    "IndexTable = pd.DataFrame({'Aspect'        : IT_Aspects,  # 'Time' and 'Element' must be present!\n",
    "                           'Description'   : IT_Description,\n",
    "                           'Dimension'     : IT_Dimension,\n",
    "                           'Classification': [ModelClassification[Aspect] for Aspect in IT_Aspects],\n",
    "                           'IndexLetter'   : IT_IndexLetter})  # Unique one letter (upper or lower case) indices to be used later for calculations.\n",
    "\n",
    "# Default indexing of IndexTable, other indices are produced on the fly\n",
    "IndexTable.set_index('Aspect', inplace=True)\n",
    "\n",
    "# Add indexSize to IndexTable:\n",
    "IndexTable['IndexSize'] = pd.Series([len(IndexTable.Classification[i].Items) for i in range(0, len(IndexTable.IndexLetter))],\n",
    "                                    index=IndexTable.index)\n",
    "\n",
    "# list of the classifications used for each indexletter\n",
    "IndexTable_ClassificationNames = [IndexTable.Classification[i].Name for i in range(0, len(IndexTable.IndexLetter))]\n",
    "\n",
    "\n",
    "# Define dimension sizes\n",
    "Nt = len(IndexTable.Classification[IndexTable.index.get_loc('Time')].Items)\n",
    "Nc = len(IndexTable.Classification[IndexTable.index.get_loc('Age-cohort')].Items)\n",
    "Ng = len(IndexTable.Classification[IndexTable.index.get_loc('Drive_train')].Items)\n",
    "Ne = len(IndexTable.Classification[IndexTable.index.get_loc('Element')].Items)\n",
    "Nb = len(IndexTable.Classification[IndexTable.index.get_loc('Battery_Chemistry')].Items)\n",
    "Ns = len(IndexTable.Classification[IndexTable.index.get_loc('Size')].Items)\n",
    "Nh = len(IndexTable.Classification[IndexTable.index.get_loc('Recycling_Process')].Items)\n",
    "NS = len(IndexTable.Classification[IndexTable.index.get_loc('EV_penetration_scenario')].Items)\n",
    "Na = len(IndexTable.Classification[IndexTable.index.get_loc('Chemistry_Scenarios')].Items)\n",
    "Nz = len(IndexTable.Classification[IndexTable.index.get_loc('Stock_Scenarios')].Items)\n",
    "NR = len(IndexTable.Classification[IndexTable.index.get_loc('Reuse_Scenarios')].Items)\n",
    "NE = len(IndexTable.Classification[IndexTable.index.get_loc('Energy_Storage_Scenarios')].Items)\n",
    "Nv = len(IndexTable.Classification[IndexTable.index.get_loc('V2G_Scenarios')].Items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing capacity decay function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>general decay</th>\n",
       "      <th>LFP_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  general decay  LFP_decay\n",
       "96    96           0.01       0.01\n",
       "97    97           0.01       0.01\n",
       "98    98           0.01       0.01\n",
       "99    99           0.01       0.01\n",
       "100  100           0.01       0.01"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining path to raw data\n",
    "data_path = os.path.join(os.getcwd(), 'data', 'raw_data')\n",
    "# Importing data\n",
    "df = pd.read_excel('/Users/fernaag/Library/CloudStorage/Box-Box/BATMAN/Coding/V2G_in_EU/data/raw_data/degradation_curves_nsb.xlsx')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = np.arange(0,101)\n",
    "cohort = np.arange(0,101)\n",
    "matrix_general = np.zeros((101, 101))\n",
    "for t in range(len(year)):\n",
    "    for c in range(len(cohort)):\n",
    "        if t-c>=0:\n",
    "            matrix_general[t,c]=df['general decay'].values[t-c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = np.arange(0,101)\n",
    "cohort = np.arange(0,101)\n",
    "matrix_LFP = np.zeros((101, 101))\n",
    "for t in range(len(year)):\n",
    "    for c in range(len(cohort)):\n",
    "        if t-c>=0:\n",
    "            matrix_LFP[t,c]=df['LFP_decay'].values[t-c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecayArray = np.zeros((17, 101, 101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign values\n",
    "DecayArray[2,:,:] = matrix_LFP\n",
    "\n",
    "DecayArray[0,:,:] = matrix_general\n",
    "DecayArray[1,:,:]= matrix_general\n",
    "DecayArray[3,:,:]= matrix_general\n",
    "DecayArray[4,:,:]= matrix_general\n",
    "DecayArray[5,:,:]= matrix_general\n",
    "DecayArray[6,:,:]= matrix_general\n",
    "DecayArray[7,:,:]= matrix_general\n",
    "DecayArray[8,:,:]= matrix_general\n",
    "DecayArray[9,:,:]= matrix_general\n",
    "DecayArray[10,:,:]= matrix_general\n",
    "DecayArray[11,:,:]= matrix_general\n",
    "DecayArray[12,:,:]= matrix_general\n",
    "DecayArray[13,:,:]= matrix_general\n",
    "DecayArray[14,:,:]= matrix_general\n",
    "DecayArray[15,:,:]= matrix_general\n",
    "DecayArray[16,:,:]= matrix_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define results path\n",
    "np.save('/Users/fernaag/Library/CloudStorage/Box-Box/BATMAN/Coding/V2G_in_EU/data/scenario_data/degradation_nsb.npy', DecayArray, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e8bb903b252ba714497fa033a1c83530c121a2bd51e9ac4f75a54b9e1c96faa"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('IAM': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
