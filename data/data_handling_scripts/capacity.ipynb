{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('IAM': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "d2e968add10d64ad2b3be6e57835fc773ce9c934140c61480cbe8a7410362424"
   }
  },
  "interpreter": {
   "hash": "d2e968add10d64ad2b3be6e57835fc773ce9c934140c61480cbe8a7410362424"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reshaping data for model\n",
    "### In this file, we will take the data that has been gathered and harmonized and we will fit it, create scenarios, and save it as a structured array for the model. Since we would like to keep the flexibility with excel, we will also save it in an ODYM compatible format and create a file that can do the reverse: if teh excel file is eddited, so is the array. This will be a separate script"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Load a local copy of the current ODYM branch:\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn.palettes import color_palette\n",
    "import xlrd\n",
    "import pylab\n",
    "from copy import deepcopy\n",
    "import logging as log\n",
    "import xlwt\n",
    "import tqdm\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib\n",
    "from logistic import logistic as logistic\n",
    "mpl_logger = log.getLogger(\"matplotlib\")\n",
    "mpl_logger.setLevel(log.WARNING)  \n",
    "# For Ipython Notebook only\n",
    "### Preamble\n",
    "# Going to parent path\n",
    "os.getcwd()\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")\n",
    "\n",
    "# add ODYM module directory to system path, relative\n",
    "MainPath = os.path.join(os.getcwd(), 'odym', 'modules')\n",
    "sys.path.insert(0, MainPath)\n",
    "\n",
    "# add ODYM module directory to system path, absolute\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'odym', 'modules'))\n",
    "\n",
    "# Specify path to dynamic stock model and to datafile, relative\n",
    "DataPath = os.path.join( 'docs', 'files')\n",
    "\n",
    "# Specify path to dynamic stock model and to datafile, absolute\n",
    "DataPath = os.path.join(os.getcwd(), 'docs', 'Files')\n",
    "\n",
    "import ODYM_Classes as msc # import the ODYM class file\n",
    "import ODYM_Functions as msf # import the ODYM function file\n",
    "import dynamic_stock_model as dsm # import the dynamic stock model library\n",
    "\n",
    "# Initialize loggin routine\n",
    "log_verbosity = eval(\"log.DEBUG\")\n",
    "log_filename = 'LogFileTest.md'\n",
    "[Mylog, console_log, file_log] = msf.function_logger(log_filename, os.getcwd(),\n",
    "                                                     log_verbosity, log_verbosity)\n",
    "Mylog.info('### 1. - Initialize.')\n",
    "\n",
    "#Read main script parameters\n",
    "#Load project-specific config file\n",
    "ProjectSpecs_ConFile = 'ODYM_Config_Vehicle_System.xlsx'\n",
    "Model_Configfile     = xlrd.open_workbook(os.path.join(DataPath, ProjectSpecs_ConFile))\n",
    "ScriptConfig         = {'Model Setting': Model_Configfile.sheet_by_name('Config').cell_value(3,3)} # Dictionary with config parameters\n",
    "Model_Configsheet    = Model_Configfile.sheet_by_name('Setting_' + ScriptConfig['Model Setting'])\n",
    "\n",
    "Name_Scenario        = Model_Configsheet.cell_value(3,3)\n",
    "print(Name_Scenario)\n",
    "\n",
    "#Read control and selection parameters into dictionary\n",
    "ScriptConfig         = msf.ParseModelControl(Model_Configsheet,ScriptConfig)\n",
    "\n",
    "Mylog.info('Read and parse config table, including the model index table, from model config sheet.')\n",
    "IT_Aspects,IT_Description,IT_Dimension,IT_Classification,IT_Selector,IT_IndexLetter,\\\n",
    "PL_Names,PL_Description,PL_Version,PL_IndexStructure,PL_IndexMatch,PL_IndexLayer,\\\n",
    "PrL_Number,PrL_Name,PrL_Comment,PrL_Type,ScriptConfig = msf.ParseConfigFile(Model_Configsheet,ScriptConfig,Mylog)    \n",
    "\n",
    "class_filename       = 'ODYM_Classifications_Master_Vehicle_System.xlsx'\n",
    "Classfile            = xlrd.open_workbook(os.path.join(DataPath,class_filename))\n",
    "Classsheet           = Classfile.sheet_by_name('MAIN_Table')\n",
    "MasterClassification = msf.ParseClassificationFile_Main(Classsheet,Mylog)\n",
    "\n",
    "\n",
    "Mylog.info('Define model classifications and select items for model classifications according to information provided by config file.')\n",
    "ModelClassification  = {} # Dict of model classifications\n",
    "for m in range(0,len(IT_Aspects)):\n",
    "    ModelClassification[IT_Aspects[m]] = deepcopy(MasterClassification[IT_Classification[m]])\n",
    "    EvalString = msf.EvalItemSelectString(IT_Selector[m],len(ModelClassification[IT_Aspects[m]].Items))\n",
    "    if EvalString.find(':') > -1: # range of items is taken\n",
    "        RangeStart = int(EvalString[0:EvalString.find(':')])\n",
    "        RangeStop  = int(EvalString[EvalString.find(':')+1::])\n",
    "        ModelClassification[IT_Aspects[m]].Items = ModelClassification[IT_Aspects[m]].Items[RangeStart:RangeStop]           \n",
    "    elif EvalString.find('[') > -1: # selected items are taken\n",
    "        ModelClassification[IT_Aspects[m]].Items = [ModelClassification[IT_Aspects[m]].Items[i] for i in eval(EvalString)]\n",
    "    elif EvalString == 'all':\n",
    "        None\n",
    "    else:\n",
    "        Mylog.error('Item select error for aspect ' + IT_Aspects[m] + ' were found in datafile.')\n",
    "        break\n",
    "\n",
    "# Define model index table and parameter dictionary\n",
    "Mylog.info('### 2.2 - Define model index table and parameter dictionary')\n",
    "Model_Time_Start = int(min(ModelClassification['Time'].Items))\n",
    "Model_Time_End   = int(max(ModelClassification['Time'].Items))\n",
    "Model_Duration   = Model_Time_End - Model_Time_Start + 1\n",
    "\n",
    "Mylog.info('Define index table dataframe.')\n",
    "IndexTable = pd.DataFrame({'Aspect'        : IT_Aspects,  # 'Time' and 'Element' must be present!\n",
    "                           'Description'   : IT_Description,\n",
    "                           'Dimension'     : IT_Dimension,\n",
    "                           'Classification': [ModelClassification[Aspect] for Aspect in IT_Aspects],\n",
    "                           'IndexLetter'   : IT_IndexLetter})  # Unique one letter (upper or lower case) indices to be used later for calculations.\n",
    "\n",
    "# Default indexing of IndexTable, other indices are produced on the fly\n",
    "IndexTable.set_index('Aspect', inplace=True)\n",
    "\n",
    "# Add indexSize to IndexTable:\n",
    "IndexTable['IndexSize'] = pd.Series([len(IndexTable.Classification[i].Items) for i in range(0, len(IndexTable.IndexLetter))],\n",
    "                                    index=IndexTable.index)\n",
    "\n",
    "# list of the classifications used for each indexletter\n",
    "IndexTable_ClassificationNames = [IndexTable.Classification[i].Name for i in range(0, len(IndexTable.IndexLetter))]\n",
    "\n",
    "\n",
    "# Define dimension sizes\n",
    "Nt = len(IndexTable.Classification[IndexTable.index.get_loc('Time')].Items)\n",
    "Nc = len(IndexTable.Classification[IndexTable.index.get_loc('Age-cohort')].Items)\n",
    "Ng = len(IndexTable.Classification[IndexTable.index.get_loc('Drive_train')].Items)\n",
    "Ne = len(IndexTable.Classification[IndexTable.index.get_loc('Element')].Items)\n",
    "Nb = len(IndexTable.Classification[IndexTable.index.get_loc('Battery_Chemistry')].Items)\n",
    "Ns = len(IndexTable.Classification[IndexTable.index.get_loc('Size')].Items)\n",
    "Nh = len(IndexTable.Classification[IndexTable.index.get_loc('Recycling_Process')].Items)\n",
    "NS = len(IndexTable.Classification[IndexTable.index.get_loc('EV_penetration_scenario')].Items)\n",
    "Na = len(IndexTable.Classification[IndexTable.index.get_loc('Chemistry_Scenarios')].Items)\n",
    "Nz = len(IndexTable.Classification[IndexTable.index.get_loc('Stock_Scenarios')].Items)\n",
    "NR = len(IndexTable.Classification[IndexTable.index.get_loc('Reuse_Scenarios')].Items)\n",
    "NE = len(IndexTable.Classification[IndexTable.index.get_loc('Energy_Storage_Scenarios')].Items)\n",
    "Nv = len(IndexTable.Classification[IndexTable.index.get_loc('V2G_Scenarios')].Items)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO (<ipython-input-1-fe30fc3b3d14> <<module>>): ### 1. - Initialize.\n",
      "INFO (<ipython-input-1-fe30fc3b3d14> <<module>>): Read and parse config table, including the model index table, from model config sheet.\n",
      "INFO (ODYM_Functions.py <ParseConfigFile>): Read parameter list from model config sheet.\n",
      "INFO (ODYM_Functions.py <ParseConfigFile>): Read process list from model config sheet.\n",
      "INFO (ODYM_Functions.py <ParseConfigFile>): Read model run control from model config sheet.\n",
      "INFO (ODYM_Functions.py <ParseConfigFile>): Read model output control from model config sheet.\n",
      "INFO (ODYM_Functions.py <ParseClassificationFile_Main>): End of file or formatting error while reading the classification file in column 16. Check if all classifications are present. If yes, you are good to go!\n",
      "INFO (<ipython-input-1-fe30fc3b3d14> <<module>>): Define model classifications and select items for model classifications according to information provided by config file.\n",
      "INFO (<ipython-input-1-fe30fc3b3d14> <<module>>): ### 2.2 - Define model index table and parameter dictionary\n",
      "INFO (<ipython-input-1-fe30fc3b3d14> <<module>>): Define index table dataframe.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vehicle stock model for European fleet\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing battery capacity\n",
    "We define a simple battery capacity that depends on the drive train and size of the vehicle and is constant over time. This can be justified, since batteries are reaching a point where the range is no longer a limitation and improvements in battery technologies are targeted towards reducing the battery weight rather than increasing range. This is reflected in the material content of the different battery chemistries. \n",
    "\n",
    "We anyway use an array that depends on time in case we would like to change this assumption. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "CapArray = np.zeros((Ng,Ns,Nt))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Defining empty DataFrame with the desired dimensions\n",
    "lp0, lp1, lp2 = pd.core.reshape.util.cartesian_product([IndexTable.Classification[IndexTable.index.get_loc('Drive_train')].Items,IndexTable.Classification[IndexTable.index.get_loc('Size')].Items, IndexTable.Classification[IndexTable.index.get_loc('Time')].Items])\n",
    "df = pd.DataFrame(dict(Drive_train= lp0, Size=lp1, Time=lp2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Defining path to raw data\n",
    "data_path = os.path.join(os.getcwd(), 'data', 'raw_data')\n",
    "# Importing data\n",
    "data = pd.read_excel(data_path+'/Capacity.xlsx')\n",
    "data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>drive_train</th>\n",
       "      <th>required capacity</th>\n",
       "      <th>available capacity</th>\n",
       "      <th>energy_density module level</th>\n",
       "      <th>stated_specific_energy</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Small</td>\n",
       "      <td>BEV</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0.277708</td>\n",
       "      <td>122</td>\n",
       "      <td>kWh/kg</td>\n",
       "      <td>BatPack Model, Xu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Medium</td>\n",
       "      <td>BEV</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>1.659485</td>\n",
       "      <td>384</td>\n",
       "      <td>kWh/kg</td>\n",
       "      <td>BatPack Model, Xu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Large</td>\n",
       "      <td>BEV</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1.620221</td>\n",
       "      <td>384</td>\n",
       "      <td>kWh/kg</td>\n",
       "      <td>BatPack Model, Xu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Small</td>\n",
       "      <td>PHEV</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>1.170625</td>\n",
       "      <td>327</td>\n",
       "      <td>kWh/kg</td>\n",
       "      <td>BatPack Model, Xu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Medium</td>\n",
       "      <td>PHEV</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.147216</td>\n",
       "      <td>74</td>\n",
       "      <td>kWh/kg</td>\n",
       "      <td>BatPack Model, Xu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     size drive_train  required capacity  available capacity  \\\n",
       "0   Small         BEV                 33                  33   \n",
       "1  Medium         BEV                 66                  66   \n",
       "2   Large         BEV                100                 100   \n",
       "3   Small        PHEV                 17                  17   \n",
       "4  Medium        PHEV                  8                   8   \n",
       "\n",
       "   energy_density module level  stated_specific_energy Unnamed: 6  \\\n",
       "0                     0.277708                     122     kWh/kg   \n",
       "1                     1.659485                     384     kWh/kg   \n",
       "2                     1.620221                     384     kWh/kg   \n",
       "3                     1.170625                     327     kWh/kg   \n",
       "4                     0.147216                      74     kWh/kg   \n",
       "\n",
       "              source  \n",
       "0  BatPack Model, Xu  \n",
       "1  BatPack Model, Xu  \n",
       "2  BatPack Model, Xu  \n",
       "3  BatPack Model, Xu  \n",
       "4  BatPack Model, Xu  "
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "for g in (IndexTable.Classification[IndexTable.index.get_loc('Drive_train')].Items):\n",
    "    for s in (IndexTable.Classification[IndexTable.index.get_loc('Size')].Items):\n",
    "        try: # We need this to ignore the drive trains that are not included\n",
    "            df.loc[(df['Drive_train']==g) & (df['Size']==s), 'value'] = data.loc[(data['drive_train']==g) & (data['size']==s), 'available capacity'].values[0]\n",
    "        except: \n",
    "            pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df.fillna(0, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "for m in range(0,len(df['Time'])):\n",
    "    DriveTrainPosition = IndexTable.Classification[IndexTable.index.get_loc('Drive_train')].Items.index(df['Drive_train'].iloc[m])\n",
    "    SizePosition = IndexTable.Classification[IndexTable.index.get_loc('Size')].Items.index(df['Size'].iloc[m])\n",
    "    TimePosition = IndexTable.Classification[IndexTable.index.get_loc('Time')].Items.index(df['Time'].iloc[m])\n",
    "    CapArray[DriveTrainPosition, SizePosition, TimePosition] = df['value'].iloc[m]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# define results path\n",
    "results_path = os.path.join(os.getcwd(), 'data', 'scenario_data')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Save as excel for overview\n",
    "df.to_excel(results_path+'/capacity.xlsx')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "np.save(results_path+'/capacity', CapArray, allow_pickle=True)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}