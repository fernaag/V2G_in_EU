{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('IAM': conda)"
  },
  "interpreter": {
   "hash": "d2e968add10d64ad2b3be6e57835fc773ce9c934140c61480cbe8a7410362424"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reshaping data for model\n",
    "### In this file, we will take the data that has been gathered and harmonized and we will fit it, create scenarios, and save it as a structured array for the model. Since we would like to keep the flexibility with excel, we will also save it in an ODYM compatible format and create a file that can do the reverse: if teh excel file is eddited, so is the array. This will be a separate script"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Load a local copy of the current ODYM branch:\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn.palettes import color_palette\n",
    "import xlrd\n",
    "import pylab\n",
    "from copy import deepcopy\n",
    "import logging as log\n",
    "import xlwt\n",
    "import tqdm\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib\n",
    "from logistic import logistic as logistic\n",
    "mpl_logger = log.getLogger(\"matplotlib\")\n",
    "mpl_logger.setLevel(log.WARNING)  \n",
    "# For Ipython Notebook only\n",
    "### Preamble\n",
    "# Going to parent path\n",
    "os.getcwd()\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")\n",
    "\n",
    "# add ODYM module directory to system path, relative\n",
    "MainPath = os.path.join(os.getcwd(), 'odym', 'modules')\n",
    "sys.path.insert(0, MainPath)\n",
    "\n",
    "# add ODYM module directory to system path, absolute\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'odym', 'modules'))\n",
    "\n",
    "# Specify path to dynamic stock model and to datafile, relative\n",
    "DataPath = os.path.join( 'docs', 'files')\n",
    "\n",
    "# Specify path to dynamic stock model and to datafile, absolute\n",
    "DataPath = os.path.join(os.getcwd(), 'docs', 'Files')\n",
    "\n",
    "import ODYM_Classes as msc # import the ODYM class file\n",
    "import ODYM_Functions as msf # import the ODYM function file\n",
    "import dynamic_stock_model as dsm # import the dynamic stock model library\n",
    "\n",
    "# Initialize loggin routine\n",
    "log_verbosity = eval(\"log.DEBUG\")\n",
    "log_filename = 'LogFileTest.md'\n",
    "[Mylog, console_log, file_log] = msf.function_logger(log_filename, os.getcwd(),\n",
    "                                                     log_verbosity, log_verbosity)\n",
    "Mylog.info('### 1. - Initialize.')\n",
    "\n",
    "#Read main script parameters\n",
    "#Load project-specific config file\n",
    "ProjectSpecs_ConFile = 'ODYM_Config_Vehicle_System.xlsx'\n",
    "Model_Configfile     = xlrd.open_workbook(os.path.join(DataPath, ProjectSpecs_ConFile))\n",
    "ScriptConfig         = {'Model Setting': Model_Configfile.sheet_by_name('Config').cell_value(3,3)} # Dictionary with config parameters\n",
    "Model_Configsheet    = Model_Configfile.sheet_by_name('Setting_' + ScriptConfig['Model Setting'])\n",
    "\n",
    "Name_Scenario        = Model_Configsheet.cell_value(3,3)\n",
    "print(Name_Scenario)\n",
    "\n",
    "#Read control and selection parameters into dictionary\n",
    "ScriptConfig         = msf.ParseModelControl(Model_Configsheet,ScriptConfig)\n",
    "\n",
    "Mylog.info('Read and parse config table, including the model index table, from model config sheet.')\n",
    "IT_Aspects,IT_Description,IT_Dimension,IT_Classification,IT_Selector,IT_IndexLetter,\\\n",
    "PL_Names,PL_Description,PL_Version,PL_IndexStructure,PL_IndexMatch,PL_IndexLayer,\\\n",
    "PrL_Number,PrL_Name,PrL_Comment,PrL_Type,ScriptConfig = msf.ParseConfigFile(Model_Configsheet,ScriptConfig,Mylog)    \n",
    "\n",
    "class_filename       = 'ODYM_Classifications_Master_Vehicle_System.xlsx'\n",
    "Classfile            = xlrd.open_workbook(os.path.join(DataPath,class_filename))\n",
    "Classsheet           = Classfile.sheet_by_name('MAIN_Table')\n",
    "MasterClassification = msf.ParseClassificationFile_Main(Classsheet,Mylog)\n",
    "\n",
    "\n",
    "Mylog.info('Define model classifications and select items for model classifications according to information provided by config file.')\n",
    "ModelClassification  = {} # Dict of model classifications\n",
    "for m in range(0,len(IT_Aspects)):\n",
    "    ModelClassification[IT_Aspects[m]] = deepcopy(MasterClassification[IT_Classification[m]])\n",
    "    EvalString = msf.EvalItemSelectString(IT_Selector[m],len(ModelClassification[IT_Aspects[m]].Items))\n",
    "    if EvalString.find(':') > -1: # range of items is taken\n",
    "        RangeStart = int(EvalString[0:EvalString.find(':')])\n",
    "        RangeStop  = int(EvalString[EvalString.find(':')+1::])\n",
    "        ModelClassification[IT_Aspects[m]].Items = ModelClassification[IT_Aspects[m]].Items[RangeStart:RangeStop]           \n",
    "    elif EvalString.find('[') > -1: # selected items are taken\n",
    "        ModelClassification[IT_Aspects[m]].Items = [ModelClassification[IT_Aspects[m]].Items[i] for i in eval(EvalString)]\n",
    "    elif EvalString == 'all':\n",
    "        None\n",
    "    else:\n",
    "        Mylog.error('Item select error for aspect ' + IT_Aspects[m] + ' were found in datafile.')\n",
    "        break\n",
    "\n",
    "# Define model index table and parameter dictionary\n",
    "Mylog.info('### 2.2 - Define model index table and parameter dictionary')\n",
    "Model_Time_Start = int(min(ModelClassification['Time'].Items))\n",
    "Model_Time_End   = int(max(ModelClassification['Time'].Items))\n",
    "Model_Duration   = Model_Time_End - Model_Time_Start + 1\n",
    "\n",
    "Mylog.info('Define index table dataframe.')\n",
    "IndexTable = pd.DataFrame({'Aspect'        : IT_Aspects,  # 'Time' and 'Element' must be present!\n",
    "                           'Description'   : IT_Description,\n",
    "                           'Dimension'     : IT_Dimension,\n",
    "                           'Classification': [ModelClassification[Aspect] for Aspect in IT_Aspects],\n",
    "                           'IndexLetter'   : IT_IndexLetter})  # Unique one letter (upper or lower case) indices to be used later for calculations.\n",
    "\n",
    "# Default indexing of IndexTable, other indices are produced on the fly\n",
    "IndexTable.set_index('Aspect', inplace=True)\n",
    "\n",
    "# Add indexSize to IndexTable:\n",
    "IndexTable['IndexSize'] = pd.Series([len(IndexTable.Classification[i].Items) for i in range(0, len(IndexTable.IndexLetter))],\n",
    "                                    index=IndexTable.index)\n",
    "\n",
    "# list of the classifications used for each indexletter\n",
    "IndexTable_ClassificationNames = [IndexTable.Classification[i].Name for i in range(0, len(IndexTable.IndexLetter))]\n",
    "\n",
    "\n",
    "# Define dimension sizes\n",
    "Nt = len(IndexTable.Classification[IndexTable.index.get_loc('Time')].Items)\n",
    "Nc = len(IndexTable.Classification[IndexTable.index.get_loc('Age-cohort')].Items)\n",
    "Ng = len(IndexTable.Classification[IndexTable.index.get_loc('Drive_train')].Items)\n",
    "Ne = len(IndexTable.Classification[IndexTable.index.get_loc('Element')].Items)\n",
    "Nb = len(IndexTable.Classification[IndexTable.index.get_loc('Battery_Chemistry')].Items)\n",
    "Ns = len(IndexTable.Classification[IndexTable.index.get_loc('Size')].Items)\n",
    "Nh = len(IndexTable.Classification[IndexTable.index.get_loc('Recycling_Process')].Items)\n",
    "NS = len(IndexTable.Classification[IndexTable.index.get_loc('EV_penetration_scenario')].Items)\n",
    "Na = len(IndexTable.Classification[IndexTable.index.get_loc('Chemistry_Scenarios')].Items)\n",
    "Nz = len(IndexTable.Classification[IndexTable.index.get_loc('Stock_Scenarios')].Items)\n",
    "NR = len(IndexTable.Classification[IndexTable.index.get_loc('Reuse_Scenarios')].Items)\n",
    "NE = len(IndexTable.Classification[IndexTable.index.get_loc('Energy_Storage_Scenarios')].Items)\n",
    "Nv = len(IndexTable.Classification[IndexTable.index.get_loc('V2G_Scenarios')].Items)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO (<ipython-input-1-fe30fc3b3d14> <<module>>): ### 1. - Initialize.\n",
      "INFO (<ipython-input-1-fe30fc3b3d14> <<module>>): Read and parse config table, including the model index table, from model config sheet.\n",
      "INFO (ODYM_Functions.py <ParseConfigFile>): Read parameter list from model config sheet.\n",
      "INFO (ODYM_Functions.py <ParseConfigFile>): Read process list from model config sheet.\n",
      "INFO (ODYM_Functions.py <ParseConfigFile>): Read model run control from model config sheet.\n",
      "INFO (ODYM_Functions.py <ParseConfigFile>): Read model output control from model config sheet.\n",
      "INFO (ODYM_Functions.py <ParseClassificationFile_Main>): End of file or formatting error while reading the classification file in column 16. Check if all classifications are present. If yes, you are good to go!\n",
      "INFO (<ipython-input-1-fe30fc3b3d14> <<module>>): Define model classifications and select items for model classifications according to information provided by config file.\n",
      "INFO (<ipython-input-1-fe30fc3b3d14> <<module>>): ### 2.2 - Define model index table and parameter dictionary\n",
      "INFO (<ipython-input-1-fe30fc3b3d14> <<module>>): Define index table dataframe.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vehicle stock model for European fleet\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparing capacity decay function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Defining path to raw data\n",
    "data_path = os.path.join(os.getcwd(), 'data', 'raw_data')\n",
    "# Importing data\n",
    "df = pd.read_excel(data_path+'/degradation_curves_vehicles.xlsx')\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   age  general decay  LFP_decay\n",
       "0    0       1.000000       1.00\n",
       "1    1       0.986667       0.99\n",
       "2    2       0.973333       0.98\n",
       "3    3       0.960000       0.97\n",
       "4    4       0.946667       0.96"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>general decay</th>\n",
       "      <th>LFP_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "year = np.arange(0,101)\n",
    "cohort = np.arange(0,101)\n",
    "matrix_general = np.zeros((Nt, Nt))\n",
    "for t in range(len(year)):\n",
    "    for c in range(len(cohort)):\n",
    "        if t-c>=0:\n",
    "            matrix_general[t,c]=df['general decay'].values[t-c]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "year = np.arange(0,101)\n",
    "cohort = np.arange(0,101)\n",
    "matrix_LFP = np.zeros((Nt, Nt))\n",
    "for t in range(len(year)):\n",
    "    for c in range(len(cohort)):\n",
    "        if t-c>=0:\n",
    "            matrix_LFP[t,c]=df['LFP_decay'].values[t-c]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "DecayArray = np.zeros((Nb, Nt, Nc))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Assign values\n",
    "DecayArray[2,:,:] = matrix_LFP\n",
    "\n",
    "DecayArray[0,:,:] = matrix_general\n",
    "DecayArray[1,:,:]= matrix_general\n",
    "DecayArray[3,:,:]= matrix_general\n",
    "DecayArray[4,:,:]= matrix_general\n",
    "DecayArray[5,:,:]= matrix_general\n",
    "DecayArray[6,:,:]= matrix_general\n",
    "DecayArray[7,:,:]= matrix_general\n",
    "DecayArray[8,:,:]= matrix_general\n",
    "DecayArray[9,:,:]= matrix_general\n",
    "DecayArray[10,:,:]= matrix_general\n",
    "DecayArray[11,:,:]= matrix_general\n",
    "DecayArray[12,:,:]= matrix_general\n",
    "DecayArray[13,:,:]= matrix_general\n",
    "DecayArray[14,:,:]= matrix_general\n",
    "DecayArray[15,:,:]= matrix_general"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# define results path\n",
    "results_path = os.path.join(os.getcwd(), 'data', 'scenario_data')\n",
    "np.save(results_path+'/degradation', DecayArray, allow_pickle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}