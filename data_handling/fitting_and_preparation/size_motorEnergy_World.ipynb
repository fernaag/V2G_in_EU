{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping data for model\n",
    "### In this file, we will take the data that has been gathered and harmonized and we will fit it, create scenarios, and save it as a structured array for the model. Since we would like to keep the flexibility with excel, we will also save it in an ODYM compatible format and create a file that can do the reverse: if teh excel file is eddited, so is the array. This will be a separate script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (<ipython-input-2-13ff64b1e03a> <<module>>): ### 1. - Initialize.\n",
      "INFO (<ipython-input-2-13ff64b1e03a> <<module>>): Read and parse config table, including the model index table, from model config sheet.\n",
      "INFO (ODYM_Functions.py <ParseConfigFile>): Read parameter list from model config sheet.\n",
      "INFO (ODYM_Functions.py <ParseConfigFile>): Read process list from model config sheet.\n",
      "INFO (ODYM_Functions.py <ParseConfigFile>): Read model run control from model config sheet.\n",
      "INFO (ODYM_Functions.py <ParseConfigFile>): Read model output control from model config sheet.\n",
      "INFO (ODYM_Functions.py <ParseClassificationFile_Main>): End of file or formatting error while reading the classification file in column 20. Check if all classifications are present. If yes, you are good to go!\n",
      "INFO (<ipython-input-2-13ff64b1e03a> <<module>>): Define model classifications and select items for model classifications according to information provided by config file.\n",
      "INFO (<ipython-input-2-13ff64b1e03a> <<module>>): ### 2.2 - Define model index table and parameter dictionary\n",
      "INFO (<ipython-input-2-13ff64b1e03a> <<module>>): Define index table dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicle stock model for Global fleet\n"
     ]
    }
   ],
   "source": [
    "# Load a local copy of the current ODYM branch:\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import xlrd\n",
    "import pylab\n",
    "from copy import deepcopy\n",
    "import logging as log\n",
    "import xlwt\n",
    "import tqdm\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from openpyxl import *\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import gompertz\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "### Preamble\n",
    "\n",
    "# add ODYM module directory to system path, relative\n",
    "MainPath = os.path.join('/Users/fernaag/Box/BATMAN/Coding/Global_model', 'odym', 'modules')\n",
    "sys.path.insert(0, MainPath)\n",
    "\n",
    "# add ODYM module directory to system path, absolute\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'odym', 'modules'))\n",
    "\n",
    "# Specify path to dynamic stock model and to datafile, relative\n",
    "DataPath = os.path.join( 'docs', 'files')\n",
    "\n",
    "# Specify path to dynamic stock model and to datafile, absolute\n",
    "DataPath = os.path.join('/Users/fernaag/Box/BATMAN/Coding/Global_model', 'docs', 'Files')\n",
    "\n",
    "import ODYM_Classes as msc # import the ODYM class file\n",
    "import ODYM_Functions as msf # import the ODYM function file\n",
    "import dynamic_stock_model as dsm # import the dynamic stock model library\n",
    "\n",
    "# Initialize loggin routine\n",
    "log_verbosity = eval(\"log.DEBUG\")\n",
    "log_filename = 'LogFileTest.md'\n",
    "[Mylog, console_log, file_log] = msf.function_logger(log_filename, os.getcwd(),\n",
    "                                                     log_verbosity, log_verbosity)\n",
    "Mylog.info('### 1. - Initialize.')\n",
    "\n",
    "#Read main script parameters\n",
    "#Load project-specific config file\n",
    "ProjectSpecs_ConFile = 'ODYM_Config_Vehicle_System.xlsx'\n",
    "Model_Configfile     = xlrd.open_workbook(os.path.join(DataPath, ProjectSpecs_ConFile))\n",
    "ScriptConfig         = {'Model Setting': Model_Configfile.sheet_by_name('Config').cell_value(3,3)} # Dictionary with config parameters\n",
    "Model_Configsheet    = Model_Configfile.sheet_by_name('Setting_' + ScriptConfig['Model Setting'])\n",
    "\n",
    "Name_Scenario        = Model_Configsheet.cell_value(3,3)\n",
    "print(Name_Scenario)\n",
    "\n",
    "#Read control and selection parameters into dictionary\n",
    "ScriptConfig         = msf.ParseModelControl(Model_Configsheet,ScriptConfig)\n",
    "\n",
    "Mylog.info('Read and parse config table, including the model index table, from model config sheet.')\n",
    "IT_Aspects,IT_Description,IT_Dimension,IT_Classification,IT_Selector,IT_IndexLetter,\\\n",
    "PL_Names,PL_Description,PL_Version,PL_IndexStructure,PL_IndexMatch,PL_IndexLayer,\\\n",
    "PrL_Number,PrL_Name,PrL_Comment,PrL_Type,ScriptConfig = msf.ParseConfigFile(Model_Configsheet,ScriptConfig,Mylog)    \n",
    "\n",
    "class_filename       = 'ODYM_Classifications_Master_Vehicle_System.xlsx'\n",
    "Classfile            = xlrd.open_workbook(os.path.join(DataPath,class_filename))\n",
    "Classsheet           = Classfile.sheet_by_name('MAIN_Table')\n",
    "MasterClassification = msf.ParseClassificationFile_Main(Classsheet,Mylog)\n",
    "\n",
    "Mylog.info('Define model classifications and select items for model classifications according to information provided by config file.')\n",
    "ModelClassification  = {} # Dict of model classifications\n",
    "for m in range(0,len(IT_Aspects)):\n",
    "    ModelClassification[IT_Aspects[m]] = deepcopy(MasterClassification[IT_Classification[m]])\n",
    "    EvalString = msf.EvalItemSelectString(IT_Selector[m],len(ModelClassification[IT_Aspects[m]].Items))\n",
    "    if EvalString.find(':') > -1: # range of items is taken\n",
    "        RangeStart = int(EvalString[0:EvalString.find(':')])\n",
    "        RangeStop  = int(EvalString[EvalString.find(':')+1::])\n",
    "        ModelClassification[IT_Aspects[m]].Items = ModelClassification[IT_Aspects[m]].Items[RangeStart:RangeStop]           \n",
    "    elif EvalString.find('[') > -1: # selected items are taken\n",
    "        ModelClassification[IT_Aspects[m]].Items = [ModelClassification[IT_Aspects[m]].Items[i] for i in eval(EvalString)]\n",
    "    elif EvalString == 'all':\n",
    "        None\n",
    "    else:\n",
    "        Mylog.error('Item select error for aspect ' + IT_Aspects[m] + ' were found in datafile.')\n",
    "        break\n",
    "\n",
    "# Define model index table and parameter dictionary\n",
    "Mylog.info('### 2.2 - Define model index table and parameter dictionary')\n",
    "Model_Time_Start = int(min(ModelClassification['Time'].Items))\n",
    "Model_Time_End   = int(max(ModelClassification['Time'].Items))\n",
    "Model_Duration   = Model_Time_End - Model_Time_Start + 1\n",
    "\n",
    "Mylog.info('Define index table dataframe.')\n",
    "IndexTable = pd.DataFrame({'Aspect'        : IT_Aspects,  # 'Time' and 'Element' must be present!\n",
    "                           'Description'   : IT_Description,\n",
    "                           'Dimension'     : IT_Dimension,\n",
    "                           'Classification': [ModelClassification[Aspect] for Aspect in IT_Aspects],\n",
    "                           'IndexLetter'   : IT_IndexLetter})  # Unique one letter (upper or lower case) indices to be used later for calculations.\n",
    "\n",
    "# Default indexing of IndexTable, other indices are produced on the fly\n",
    "IndexTable.set_index('Aspect', inplace=True)\n",
    "\n",
    "# Add indexSize to IndexTable:\n",
    "IndexTable['IndexSize'] = pd.Series([len(IndexTable.Classification[i].Items) for i in range(0, len(IndexTable.IndexLetter))],\n",
    "                                    index=IndexTable.index)\n",
    "\n",
    "# list of the classifications used for each indexletter\n",
    "IndexTable_ClassificationNames = [IndexTable.Classification[i].Name for i in range(0, len(IndexTable.IndexLetter))]\n",
    "\n",
    "# Define dimension sizes\n",
    "Nt = len(IndexTable.Classification[IndexTable.index.get_loc('Time')].Items)\n",
    "Nc = len(IndexTable.Classification[IndexTable.index.get_loc('Age-cohort')].Items)\n",
    "Ng = len(IndexTable.Classification[IndexTable.index.get_loc('Good')].Items)\n",
    "Nr = len(IndexTable.Classification[IndexTable.index.get_loc('Region')].Items)\n",
    "Ne = len(IndexTable.Classification[IndexTable.index.get_loc('Element')].Items)\n",
    "Nb = len(IndexTable.Classification[IndexTable.index.get_loc('Battery_Chemistry')].Items)\n",
    "Np = len(IndexTable.Classification[IndexTable.index.get_loc('Battery_Parts')].Items)\n",
    "Ns = len(IndexTable.Classification[IndexTable.index.get_loc('Size')].Items)\n",
    "Nh = len(IndexTable.Classification[IndexTable.index.get_loc('Recycling_Process')].Items)\n",
    "NS = len(IndexTable.Classification[IndexTable.index.get_loc('Scenario')].Items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing segment files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following Xi et al. we just define a constant share of vehicle sizes for our drive trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SizeArray = np.zeros((NS,Nr,Ng,Ns,Nt))\n",
    "SizeArray[:,:,1,0,:] = 0.18 # Small vehicles\n",
    "SizeArray[:,:,1,1,:] = 0.479 # Medium vehicles\n",
    "SizeArray[:,:,1,2,:] = 0.336 # Large vehicles\n",
    "SizeArray[:,:,3,0,:] = 0.226 # Small vehicles\n",
    "SizeArray[:,:,3,1,:] = 0.454 # Medium vehicles\n",
    "SizeArray[:,:,3,2,:] = 0.32 # Large vehicles\n",
    "SizeArray[:,:,2,0,:] = 0.226 # Small vehicles\n",
    "SizeArray[:,:,2,1,:] = 0.454 # Medium vehicles\n",
    "SizeArray[:,:,2,2,:] = 0.32 # Large vehicles\n",
    "SizeArray[:,:,0,0,:] = 0.18 # Small vehicles\n",
    "SizeArray[:,:,0,1,:] = 0.479 # Medium vehicles\n",
    "SizeArray[:,:,0,2,:] = 0.336 # Large vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Users/fernaag/Box/BATMAN/Data/Database/data/03_scenario_data/global_model/vehicle_size/vehicleSize_motorEnergy_passengerCars', SizeArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d2e968add10d64ad2b3be6e57835fc773ce9c934140c61480cbe8a7410362424"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('IAM': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}